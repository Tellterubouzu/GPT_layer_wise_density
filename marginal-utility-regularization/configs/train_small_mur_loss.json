{
  "run_name": "auto",
  "output_dir": "runs/{run_name}",
  "dataset_name": "openwebtext",
  "dataset_config": null,
  "text_column": "text",
  "train_split": "train[:0.5%]",
  "eval_split": "train[:0.1%]",
  "block_size": 256,
  "batch_size": 2,
  "eval_batch_size": 2,
  "learning_rate": 5e-05,
  "weight_decay": 0.01,
  "num_train_steps": 200,
  "warmup_steps": 20,
  "eval_steps": 50,
  "save_steps": 200,
  "log_steps": 10,
  "gradient_accumulation_steps": 1,
  "max_grad_norm": 1.0,
  "seed": 42,
  "mur": {
    "enabled": true,
    "mode": "loss",
    "metric": "cos",
    "mid_start": 0.33,
    "mid_end": 0.67,
    "tau": 0.1,
    "lambda_max": 0.1,
    "alpha": 0.0,
    "warmup_steps": 20,
    "ramp_steps": 100,
    "token_reduce": "sample_k",
    "sample_k": 32,
    "eps": 1e-06,
    "fp32_dot": true,
    "log_layer_stats": false
  },
  "tokenizer_name": "meta-llama/Llama-2-7b-hf",
  "model": {
    "arch": "gpt2",
    "vocab_size": 32000,
    "hidden_size": 768,
    "num_layers": 12,
    "num_heads": 12,
    "intermediate_size": 3072,
    "max_position_embeddings": 1024,
    "attn_dropout": 0.1,
    "resid_dropout": 0.1,
    "embd_dropout": 0.1,
    "tie_word_embeddings": true,
    "bos_token_id": 1,
    "eos_token_id": 2
  }
}